\documentclass[11pt]{article}
\title{Comparison of Convolutional Neural Networks for Remote Sensing}
\date{2018-05-09}
\author{James Hurt}
\usepackage[margin=1.0in]{geometry}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{cleveref}
\usepackage{indentfirst}
\begin{document}
	\pagenumbering{arabic}
	
	%%%%%%%%%%%%%%%%
	% Title 
	%%%%%%%%%%%%%%%%
	\begin{flushright}
		James Hurt\break
		CS 8780\break
		9 May 2018
	\end{flushright}
	\begin{center}
		\huge{Comparison of Convolutional Neural Networks for Remote Sensing}
	\end{center}
	
	%%%%%%%%%%%%%%%%%%%%%%%
	% Technical Description
	%%%%%%%%%%%%%%%%%%%%%%%

	\begin{figure}[b!]
			\centering
			\begin{subfigure}[b]{0.3\linewidth}
				\centering
				\includegraphics[scale=0.38]{img/custom_arc.png}
				\caption{Custom Shallow CNN}
				\label{fig:shallow_cnn}
			\end{subfigure}
			\begin{subfigure}[b]{0.3\linewidth}
				\centering
				\includegraphics[scale=0.34]{img/vgg.png}
				\caption{VGG19}
			    \label{fig:deep_cnn}
			\end{subfigure}
			\begin{subfigure}[b]{0.3\linewidth}
				\centering
				\includegraphics[scale=0.25]{img/res50.png}
				\caption{ResNet-50}
				\label{fig:deep_rnn}
			\end{subfigure}
			\caption{Architectures of the Compared CNN}
			\label{fig:architecture}
		\end{figure}

	\section{Technical Description}
	
Remote Sensing is a lucrative application for computational intelligence, with much of the recent research being in Convolutional Neural Networks. Within this discussion of neural networks for remote sensing, Deep Convolutional Neural Networks (DCNN) are the most popular. The popularity of convolutional neural networks can be attributed to the ability of a convolutional network to learn the features of the image, thus eliminating one of the greatest challenges in all of machine learning: feature selection and extraction. While CNN have proven very useful, one of the issues with DCNN is the high training time, even with GPU acceleration. In this project, I attempt to compare a shallow convolutional network with one of the first deep convolutional networks. I then take my comparison one step farther, by looking at the relative cost and benefit of residual neural networks. 
		
I chose to make my comparison of CNN for the application of Remote Sensing because I am very interested in Remote Sensing. I think the ability to detect object from satellite imagery has many applications in every day life and can better the lives of common people as well as aid industry in understanding what is around their facilities. 
		
		\subsection{Shallow Convolutional Neural Network}
		
The shallow convolutional neural network used in this project combines many techniques of fully connected networks previously used for pattern recognition. The architecture of the network can be see in \Cref{fig:shallow_cnn}.
		
The architecture of the network has a total of 12 layers. The first 10 layers are alternating 2D Convolutional layers layers with a 3x3 kernel size and 2D Max Pooling layers with a 2x2 Pooling Window. After these 10 layers, feature extraction is finished, and a flattening layer is introduced to put the data into a single vector for the final fully connected softmax layer. 
		
		
		\subsection{Deep Convolutional Neural Network}
		
The Deep Convolutional Neural Network used for comparison in this project is VGG 19 \cite{vgg}. The VGG 19 network, as the name suggests, has 19 total layers. This count, however, does not include the pooling layers. The basic architecture can been seen in \Cref{fig:deep_cnn}. 

VGG19 has 16 convolutional layers and 4 pooling layers. The interesting quality about VGG19 is that the final pooling layer does not connect directly to the softmax output layer. Instead, the final pooling layer is a 3-layer multilayer perceptron (MLP) \cite{ci_book} The final layer of this MLP is a softmax layer for classification. 

		\subsection{Deep Residual Convolutional Neural Network}

The final neural network used for comparison in this project is a Deep Residual Convolutional Neural Network (DRNN). I chose to use ResNet-50 \cite{resnet50}, a standard DRNN for comparison developed by Microsoft Research. The architecture of this network can be seen in \Cref{fig:deep_rnn}.

ResNet-50 begins with a single convolutional layer, followed by a single pooling layer, followed by 49 convolutional layers that are residual, meaning that there is a connection from layer \textit{N} to both layer \textit{N+1} as well as layer \textit{N+2}. This connection exists so that the error from the two connections to the \textit{N+2} layer can be summed when performing backpropagation, thus slowing the disappearance of the gradient. The disappearing gradient is one of the greatest challenges of using the gradient descent method. 
	
	\section{Algorithm Design}
	
	\begin{figure}[t!]
		\centering
		\includegraphics[width=0.5\linewidth]{img/ucm.png}
		\caption{UCMerced Dataset with 21 classes}
		\label{fig:ucm}
	\end{figure}
	
	\subsection{Dataset Selection}
The algorithm I designed for comparing these various CNN involved 2 datasets: a 3 class dataset and the benchmark UC Merced Dataset \cite{ucm}. The 3 class problem is a subset of the UCMerced dataset. I chose 3 classes from the UCMerced dataset: agricultural, airplane, and baseball diamond. While the test dataset is small, the UCMerced dataset, seen in \Cref{fig:ucm} is not. It has 21 classes, each with 100 images each. This dataset is not the largest available as far as benchmark Remote Sensing is concerned, but I felt it was a good representative for my comparison, because I didn't want too challenging a dataset. 

I chose to use 2 datasets because I felt that using only one would not give me enough of a picture to draw conclusions. Perhaps, if I had chosen just one dataset, the dataset I picked was particularly suited to one of these methods, but if I chose 2, then I would have enough to draw somewhat of a conclusion. Certainly, only 2 datasets is not enough for a generalization, but it does allow me to eliminate the possibility of choosing a biased dataset.

I also chose to have a small and large dataset, because there are many instances of binary classification needed in everyday life, so looking at a 3 class problem as well as a large, 21 class problem, would allow me to see if one method was better for large but not small or vice versa. If I found that the shallow could better handle the 3 class problem or maybe if the shallow CNN was within 1\% cross validation accuracy, for example, then I could say that binary classifiers could settle for a shallow CNN, thus relieving the long training times required for Deep CNN or RNN. 

	\subsection{Parameter Selection}
	\subsection{Comparison Algorithm}


	
	\section{Experiment Results}
	
	\subsection{Test Dataset}
	\subsection{UCMerced Dataset}
	
	\section{Analysis}
	
	\section{Code}
	
	The code for this project can be seen in the \textbf{Code} folder. 
	
	
%%%%%%%%%%%%%%%%
%		 REFERENCES
%%%%%%%%%%%%%%%%%
	\newpage
	\bibliography{bibliography} 
	\bibliographystyle{ieeetr}




\end{document}